{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "# created by Phoebe_px on 2017/6/26\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#字符日期转换成datetime日期型\n",
    "def  convert2date(date):\n",
    "    date=str(date)\n",
    "    try:\n",
    "        return datetime.strptime(date,'%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        return np.datetime64('NaT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EDA过后，将 rank 当作类别变量处理 \n",
    "def convert_rank(rank):\n",
    "    if rank==3:\n",
    "        return 1\n",
    "    elif rank==5:\n",
    "        return 2\n",
    "    elif rank==7:\n",
    "        return 3\n",
    "    elif rank==9:\n",
    "        return 4\n",
    "    elif (rank>9 and rank<=15):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#脏数据列，EDA 发现‘user_confirmtime’列存在部分数据值大于0，此处我将其直接取负；同样的处理对于’user_avgadvanceddate’列\n",
    "def dirty_advaceddate(data):\n",
    "    if data<0:\n",
    "        return -data\n",
    "    else:\n",
    "        return data\n",
    "def dirty_confirmtime(data):\n",
    "    if data>0:\n",
    "        return -data\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清洗数据，增加特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(datadir,istrain=True):\n",
    "    data=pd.read_csv(datadir,delimiter='\\t')\n",
    "    cleandir='../dataset/cleandata/'\n",
    "    origin_feature=data.columns\n",
    "    if not os.path.exists('../dataset/origin_feature.pkl'):\n",
    "        pickle.dump(origin_feature,open('../dataset/origin_feature.pkl','wb'))\n",
    "    if len(os.listdir(cleandir))<=2:\n",
    "        #lastord date diff\n",
    "        data['diff_date']=(((data['orderdate'].map(convert2date)).sub(data['orderdate_lastord'].map(convert2date),axis=0)).astype(timedelta).map(lambda x: np.nan if pd.isnull(x) else x.days))\n",
    "        #rank split to six class (3，5,7,9,11-15，>15)\n",
    "        data['rank']=data['rank'].map(convert_rank)\n",
    "        data['rank_lastord']=data['rank_lastord'].map(convert_rank)\n",
    "        #diff between rank 、hotelid 、 basicroomid 、roomid 、star\n",
    "        data['rank_diff']=(data['rank']==data['rank_lastord']).map(int)\n",
    "        data['hotel_diff']=(data.hotelid==data.hotelid_lastord).astype(int)\n",
    "        data['basicroomid_diff']=(data.basicroomid==data.basicroomid_lastord).astype(int)\n",
    "        data['roomid_diff']=(data.roomid==data.roomid_lastord).astype(int)\n",
    "        data['star_diff']=(data['star']==data['star_lastord']).map(int)\n",
    "        #clean dirty data\n",
    "        data['user_avgadvanceddate']=data['user_avgadvanceddate'].map(dirty_advaceddate)\n",
    "        data['user_confirmtime']=data['user_confirmtime'].map(dirty_confirmtime)\n",
    "        #discount ratio\n",
    "        data['discount_lastord']=data['return_lastord']/data['price_last_lastord']\n",
    "        data['discount']=data['returnvalue']/data['price_deduct']\n",
    "        data['discount_gap']=data['discount']-data['discount_lastord']\n",
    "        #price diff\n",
    "        data['price_gap']=(data['price_deduct']-data['returnvalue'])-(data['price_last_lastord']-data['return_lastord'])\n",
    "        #last order gap in price and hotel_minprice、basic_minprice \n",
    "        data['pirce_hotelmin_last_gap']=(data['price_last_lastord'])-(data['hotel_minprice_lastord'])\n",
    "        data['price_basicmin_last_gap']=(data['price_last_lastord'])-(data['basic_minprice_lastord'])\n",
    "        #diff roomservice\n",
    "        data['roomservice_2_gap']=data['roomservice_2']-data['roomservice_2_lastord']\n",
    "        data['roomservice_3_gap']=data['roomservice_3']-data['roomservice_3_lastord']\n",
    "        data['roomservice_4_gap']=data['roomservice_4']-data['roomservice_4_lastord']\n",
    "        data['roomservice_5_gap']=data['roomservice_5']-data['roomservice_5_lastord']\n",
    "        data['roomservice_6_gap']=data['roomservice_6']-data['roomservice_6_lastord']\n",
    "        data['roomservice_8_gap']=data['roomservice_8']-data['roomservice_8_lastord']\n",
    "        #diff roomtag\n",
    "        data['roomtag_2_gap']=data['roomtag_2']-data['roomtag_2_lastord']\n",
    "        data['roomtag_3_gap']=data['roomtag_3']-data['roomtag_3_lastord']\n",
    "        data['roomtag_4_gap']=(data['roomtag_4']==data['roomtag_4_lastord']).map(int)\n",
    "        data['roomtag_5_gap']=(data['roomtag_5']==data['roomtag_5_lastord']).map(int)\n",
    "        data['roomtag_6_gap']=(data['roomtag_6']==data['roomtag_6_lastord']).map(int)\n",
    "        # gap in price and hotel_minprice、basic_minprice \n",
    "        temp=data[['orderid','uid','hotelid','basicroomid','roomid','price_deduct']]\n",
    "        temp['price_deduct']=temp['price_deduct']\n",
    "        df_hotel_minprice=temp.groupby(['orderid','uid','hotelid'],as_index=False).min().rename(columns={'price_deduct': 'hotel_minprice'})[['orderid','uid','hotelid','hotel_minprice']]\n",
    "        df_basci_minprice=temp.groupby(['orderid','uid','hotelid','basicroomid'],as_index=False).min().rename(columns={'price_deduct': 'basic_minprice'})[['orderid','uid','hotelid','basicroomid','basic_minprice']]\n",
    "        data=pd.merge(data,df_hotel_minprice,how='left', on=['orderid','uid','hotelid'])\n",
    "        data=pd.merge(data,df_basci_minprice,how='left',on=['orderid','uid','hotelid','basicroomid'])\n",
    "        data['pirce_hotelmin_gap']=(data['price_deduct'])-(data['hotel_minprice'])\n",
    "        data['price_basicmin_gap']=(data['price_deduct'])-(data['basic_minprice'])\n",
    "        # add features list\n",
    "        newcol=list(set(list(data.columns)).difference(set(origin_feature)))+['orderid','roomid']\n",
    "        #string type columns\n",
    "        strCols=['orderid','uid','orderdate','hotelid','basicroomid','roomid','orderid_lastord','orderdate_lastord','hotelid_lastord','roomid_lastord','basicroomid_lastord']\n",
    "        #class type features\n",
    "        classCols=['star', 'rank','rank_diff','hotel_diff','basicroomid_diff','roomservice_1', 'roomservice_2', 'roomservice_3', 'roomservice_4', 'roomservice_5', 'roomservice_6', 'roomservice_7', 'roomservice_8', 'roomtag_1', 'roomtag_4', 'roomtag_5', 'roomtag_6','roomservice_2_lastord','roomservice_3_lastord','roomservice_4_lastord','roomservice_5_lastord','roomservice_6_lastord','roomservice_8_lastord','roomtag_4_lastord','roomtag_5_lastord','roomtag_6_lastord','star_lastord','rank_lastord','roomtag_4_gap','roomtag_5_gap','roomtag_6_gap']\n",
    "        # trash features\n",
    "        delCols=['orderdate','orderid_lastord','orderbehavior_3_ratio_1month','orderbehavior_4_ratio_1month','orderbehavior_5_ratio_1month']\n",
    "        #standard scale\n",
    "        numCols=list(set(list(data.columns)).difference(set(strCols+classCols+delCols+['orderlabel'])))\n",
    "        for co in numCols:\n",
    "            data[co]=(data[co]-data[co].mean())/data[co].std(ddof=0)\n",
    "            \n",
    "        #one-hot encode\n",
    "        for co in classCols:\n",
    "            data = pd.concat([data,pd.get_dummies(data[co].fillna(-1), prefix=co)],axis=1)\n",
    "\n",
    "        if istrain:\n",
    "            data.to_csv(cleandir+'cleantrain.csv',index=None)\n",
    "        else:\n",
    "            data.to_csv(cleandir+'cleantest.csv',index=None)\n",
    "    else:\n",
    "        if istrain:\n",
    "            data=pd.read_csv(cleandir+'cleantrain.csv')\n",
    "        else:\n",
    "            data=pd.read_csv(cleandir+'cleantest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 产生训练集、测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes：** `train1，train2`分别是训练集中4月14-16日、4月18-20日的`[feature,label]`矩阵（DataFrame）,`train_val`是训练集中4月17日的`[feature,label]`矩阵，用于验证模型，评估准确性，`train_val_index`是对应的`['orderid','roomid','orderlabel']`,`test`是处理后的测试集的feature矩阵,`test_index`与test相对应的`['orderid','roomid']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gene_trainset():\n",
    "    if not os.path.exists('../dataset/train_and_pred/train1.csv'):\n",
    "        data=pd.read_csv('../dataset/cleandata/cleantrain.csv')\n",
    "        pos=data.loc[data['orderlabel']==1]\n",
    "        # Reduce negative samples\n",
    "        neg=data.loc[(data['price_deduct']>=-3)&(data['price_deduct']<=3)&(data['orderlabel']==0)]\n",
    "        data=pd.concat([pos,neg],axis=0,ignore_index=True)\n",
    "        strCols=['orderid','uid','orderdate','hotelid','basicroomid','roomid','orderid_lastord','orderdate_lastord','hotelid_lastord','roomid_lastord','basicroomid_lastord']\n",
    "        classCols=['star', 'rank','roomservice_1', 'roomservice_2', 'roomservice_3', 'roomservice_4', 'roomservice_5', 'roomservice_6', 'roomservice_7', 'roomservice_8', 'roomtag_1', 'roomtag_4', 'roomtag_5', 'roomtag_6','roomservice_2_lastord','roomservice_3_lastord','roomservice_4_lastord','roomservice_5_lastord','roomservice_6_lastord','roomservice_8_lastord','roomtag_4_lastord','roomtag_5_lastord','roomtag_6_lastord','star_lastord','rank_lastord','roomtag_4_gap','roomtag_5_gap','roomtag_6_gap']\n",
    "        delCols=['orderdate','orderid_lastord','orderbehavior_3_ratio_1month','orderbehavior_4_ratio_1month','orderbehavior_5_ratio_1month']\n",
    "        #according to orderdate split training set to 3 parts ,train_val for evaluation\n",
    "        train1=data.loc[data.orderdate.isin(['2013-04-14', '2013-04-15', '2013-04-16'])].drop(strCols+classCols+delCols,axis=1)\n",
    "        train2=data.loc[data.orderdate.isin(['2013-04-18', '2013-04-19', '2013-04-20'])].drop(strCols+classCols+delCols,axis=1)\n",
    "        train_val=data.loc[data.orderdate=='2013-04-17']\n",
    "\n",
    "        train_val_index=train_val[['orderid','roomid']]\n",
    "        train_val=train_val.drop(strCols+classCols+delCols,axis=1)\n",
    "        train1.to_csv('../dataset/train_and_pred/train1.csv',index=None)\n",
    "        train2.to_csv('../dataset/train_and_pred/train2.csv',index=None)\n",
    "        train_val.to_csv('../dataset/train_and_pred/train_val.csv',index=None)\n",
    "        train_val_index.to_csv('../dataset/train_and_pred/train_val_index.csv',index=None)\n",
    "    else:\n",
    "        train1=pd.read_csv('../dataset/train_and_pred/train1.csv')\n",
    "        train2=pd.read_csv('../dataset/train_and_pred/train2.csv')\n",
    "        train_val=pd.read_csv('../dataset/train_and_pred/train_val.csv')\n",
    "        train_val_index=pd.read_csv('../dataset/train_and_pred/new_train_val_index.csv')\n",
    "    return train1,train2,train_val,train_val_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gene_testset():\n",
    "    if not os.path.exists('../dataset/train_and_pred/test_feature.csv'):\n",
    "        data=pd.read_csv('../dataset/cleandata/cleantest.csv')\n",
    "        data=data.loc[(data['price_deduct']>=-3)&(data['price_deduct']<=3)]\n",
    "        strCols=['orderid','uid','orderdate','hotelid','basicroomid','roomid','orderid_lastord','orderdate_lastord','hotelid_lastord','roomid_lastord','basicroomid_lastord']\n",
    "        classCols=['star', 'rank','roomservice_1', 'roomservice_2', 'roomservice_3', 'roomservice_4', 'roomservice_5', 'roomservice_6', 'roomservice_7', 'roomservice_8', 'roomtag_1', 'roomtag_4', 'roomtag_5', 'roomtag_6','roomservice_2_lastord','roomservice_3_lastord','roomservice_4_lastord','roomservice_5_lastord','roomservice_6_lastord','roomservice_8_lastord','roomtag_4_lastord','roomtag_5_lastord','roomtag_6_lastord','star_lastord','rank_lastord','roomtag_4_gap','roomtag_5_gap','roomtag_6_gap']\n",
    "        delCols=['orderdate','orderid_lastord','orderbehavior_3_ratio_1month','orderbehavior_4_ratio_1month','orderbehavior_5_ratio_1month']\n",
    "        data_index=data[['orderid','roomid']]\n",
    "        data=data.drop(strCols+classCols+delCols,axis=1)\n",
    "        data.to_csv('../dataset/train_and_pred/test_feature.csv',index=None)\n",
    "        data_index.to_csv('../dataset/train_and_pred/test_index.csv',index=None)\n",
    "    else:\n",
    "        data=pd.read_csv('../dataset/train_and_pred/test_feature.csv')\n",
    "        data_index=pd.read_csv('../dataset/train_and_pred/test_index.csv')\n",
    "    return data,data_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进一步增加特征，产生训练集、测试集 （feature - label ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#futher generate features\n",
    "def further_clean_data(datadir,istrain=True):\n",
    "    data = pd.read_csv(datadir, delimiter='\\t')\n",
    "    cleandir = '../dataset/cleandata/'\n",
    "    origin_feature = list(data.columns)\n",
    "    if len(os.listdir(cleandir))<=4:\n",
    "        #gap in rank vs. avg_rank 、star vs. avg_star,avggoldstar,avgrecommendlevel\n",
    "        data['rank_avg_diff']=data['rank']-data['user_rank_ratio']\n",
    "        data['star_avg_diff']=data['star']-data['user_avgstar']\n",
    "        data['star_avggold_diff']=data['star']-data['user_avggoldstar']\n",
    "        data['star_recommend_diff']=data['star']-data['user_avgrecommendlevel']\n",
    "        #gap in avgroomarea vs. minarea,maxarea\n",
    "        data['compare_basic_minarea']=data['user_avgroomarea']-data['basic_minarea']\n",
    "        data['compare_basic_maxarea'] = data['basic_maxarea'] - data['user_avgroomarea']\n",
    "        # roomservice_4 and roomservice_6 is or not max ratio\n",
    "        df_roomservice_4=data[['user_roomservice_4_0ratio','user_roomservice_4_1ratio','user_roomservice_4_2ratio','user_roomservice_4_3ratio','user_roomservice_4_4ratio','user_roomservice_4_5ratio']]\n",
    "        data['roomservice_4_ismax']=(data['roomservice_4']==(df_roomservice_4.idxmax(axis=1).apply(lambda x: list(df_roomservice_4.columns).index(x) if x in list(df_roomservice_4.columns) else np.nan))).astype(int)\n",
    "        df_roomservice_6 = data[['user_roomservice_6_0ratio', 'user_roomservice_6_1ratio', 'user_roomservice_6_2ratio']]\n",
    "        data['roomservice_6_ismax']=(data['roomservice_6']==(df_roomservice_6.idxmax(axis=1).apply(lambda x: list(df_roomservice_6.columns).index(x) if x in list(df_roomservice_6.columns) else np.nan))).astype(int)\n",
    "        #price gap in holiday and workday\n",
    "        data['compare_price_holiday']=data['price_deduct']-data['user_avgdealpriceholiday']\n",
    "        data['compare_price_workday'] = data['price_deduct'] - data['user_avgdealpriceworkday']\n",
    "        data['compare_price_aveprice']=data['price_deduct']-data['user_avgprice']\n",
    "        data['compare_price_max']=data['user_maxprice']-data['price_deduct']\n",
    "        #basic_comment_ratio scale and Partition\n",
    "        data['basic_comment_ratio'] = (data['basic_comment_ratio'] - 0) / (data['basic_comment_ratio'].max() - 0)\n",
    "        data['basic_comment_ratio'] = data['basic_comment_ratio'].apply(lambda p: -1 if p < 0 else round(p, 1))\n",
    "\n",
    "        #new cols to standard\n",
    "        addCols=list(set(list(data.columns)).difference(set(origin_feature)))+['basic_comment_ratio']\n",
    "        newfeature=addCols+['orderid','roomid']\n",
    "        addCols.remove('roomservice_4_ismax');addCols.remove('roomservice_6_ismax');addCols.remove('basic_comment_ratio')\n",
    "        for co in addCols:\n",
    "            data[co] = (data[co] - data[co].mean()) / data[co].std(ddof=0)\n",
    "        data=data[newfeature]\n",
    "        if istrain:\n",
    "            data.to_csv(cleandir+'cleantrain2.csv',index=None)\n",
    "        else:\n",
    "            data.to_csv(cleandir+'cleantest2.csv',index=None)\n",
    "    else:\n",
    "        if istrain:\n",
    "            data=pd.read_csv(cleandir+'cleantrain2.csv')\n",
    "        else:\n",
    "            data=pd.read_csv(cleandir+'cleantest2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gene_trainset2():\n",
    "    if not os.path.exists('../dataset/train_and_pred/new_train1.csv'):\n",
    "        data1 = pd.read_csv('../dataset/cleandata/cleantrain.csv').drop('basic_comment_ratio',axis=1)\n",
    "        data2 = pd.read_csv('../dataset/cleandata/cleantrain2.csv')\n",
    "        data=pd.merge(data1,data2,how='left',on=['orderid','roomid'])\n",
    "        pos = data.loc[data['orderlabel'] == 1]\n",
    "        neg = data.loc[(data['price_deduct'] >= -3) & (data['price_deduct'] <= 3) & (data['orderlabel'] == 0)]\n",
    "        data = pd.concat([pos, neg], axis=0, ignore_index=True)\n",
    "        strCols = ['orderid', 'uid', 'orderdate', 'hotelid', 'basicroomid', 'roomid', 'orderid_lastord',\n",
    "                   'orderdate_lastord', 'hotelid_lastord', 'roomid_lastord', 'basicroomid_lastord']\n",
    "        classCols = ['star', 'rank', 'roomservice_1', 'roomservice_2', 'roomservice_3', 'roomservice_4',\n",
    "                     'roomservice_5', 'roomservice_6', 'roomservice_7', 'roomservice_8', 'roomtag_1', 'roomtag_4',\n",
    "                     'roomtag_5', 'roomtag_6', 'roomservice_2_lastord', 'roomservice_3_lastord',\n",
    "                     'roomservice_4_lastord', 'roomservice_5_lastord', 'roomservice_6_lastord', 'roomservice_8_lastord',\n",
    "                     'roomtag_4_lastord', 'roomtag_5_lastord', 'roomtag_6_lastord', 'star_lastord', 'rank_lastord',\n",
    "                     'roomtag_4_gap', 'roomtag_5_gap', 'roomtag_6_gap']\n",
    "        delCols = ['orderdate', 'orderid_lastord', 'orderbehavior_3_ratio_1month', 'orderbehavior_4_ratio_1month',\n",
    "                   'orderbehavior_5_ratio_1month']\n",
    "        train1 = data.loc[data.orderdate.isin(['2013-04-14', '2013-04-15', '2013-04-16'])].drop(\n",
    "            strCols + classCols + delCols, axis=1)\n",
    "        train2 = data.loc[data.orderdate.isin(['2013-04-18', '2013-04-19', '2013-04-20'])].drop(\n",
    "            strCols + classCols + delCols, axis=1)\n",
    "        train_val = data.loc[data.orderdate == '2013-04-17']\n",
    "        train_val_index = train_val[['orderid', 'roomid','orderlabel']]\n",
    "        train_val = train_val.drop(strCols + classCols + delCols, axis=1)\n",
    "        train1.to_csv('../dataset/train_and_pred/new_train1.csv', index=None)\n",
    "        train2.to_csv('../dataset/train_and_pred/new_train2.csv', index=None)\n",
    "        train_val.to_csv('../dataset/train_and_pred/new_train_val.csv', index=None)\n",
    "        train_val_index.to_csv('../dataset/train_and_pred/recent_train_val_index.csv', index=None)\n",
    "    else:\n",
    "        train1 = pd.read_csv('../dataset/train_and_pred/new_train1.csv')\n",
    "        train2 = pd.read_csv('../dataset/train_and_pred/new_train2.csv')\n",
    "        train_val = pd.read_csv('../dataset/train_and_pred/new_train_val.csv')\n",
    "        train_val_index = pd.read_csv('../dataset/train_and_pred/recent_train_val_index.csv')\n",
    "    return train1, train2, train_val, train_val_index\n",
    "\n",
    "def gene_testset2():\n",
    "    if not os.path.exists('../dataset/train_and_pred/new_test_feature.csv'):\n",
    "        data1=pd.read_csv('../dataset/cleandata/cleantest.csv').drop('basic_comment_ratio',axis=1)\n",
    "        data2 = pd.read_csv('../dataset/cleandata/cleantest2.csv')\n",
    "        data = pd.merge(data1, data2, how='left', on=['orderid', 'roomid'])\n",
    "        data=data.loc[(data['price_deduct']>=-3)&(data['price_deduct']<=3)]\n",
    "        strCols=['orderid','uid','orderdate','hotelid','basicroomid','roomid','orderid_lastord','orderdate_lastord','hotelid_lastord','roomid_lastord','basicroomid_lastord']\n",
    "        classCols=['star', 'rank','roomservice_1', 'roomservice_2', 'roomservice_3', 'roomservice_4', 'roomservice_5', 'roomservice_6', 'roomservice_7', 'roomservice_8', 'roomtag_1', 'roomtag_4', 'roomtag_5', 'roomtag_6','roomservice_2_lastord','roomservice_3_lastord','roomservice_4_lastord','roomservice_5_lastord','roomservice_6_lastord','roomservice_8_lastord','roomtag_4_lastord','roomtag_5_lastord','roomtag_6_lastord','star_lastord','rank_lastord','roomtag_4_gap','roomtag_5_gap','roomtag_6_gap']\n",
    "        delCols=['orderdate','orderid_lastord','orderbehavior_3_ratio_1month','orderbehavior_4_ratio_1month','orderbehavior_5_ratio_1month']\n",
    "        data_index=data[['orderid','roomid']]\n",
    "        data=data.drop(strCols+classCols+delCols,axis=1)\n",
    "        data.to_csv('../dataset/train_and_pred/new_test_feature.csv',index=None)\n",
    "        data_index.to_csv('../dataset/train_and_pred/new_test_index.csv',index=None)\n",
    "    else:\n",
    "        data=pd.read_csv('../dataset/train_and_pred/new_test_feature.csv')\n",
    "        data_index=pd.read_csv('../dataset/train_and_pred/new_test_index.csv')\n",
    "    return data,data_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV 对XGboost 调参，auc最大的参数训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgbmodel_train(train):\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    train_feature, train_label = train.drop('orderlabel', axis=1), train['orderlabel']\n",
    "\n",
    "    parameters = {'nthread': [4],\n",
    "                  'objective': ['binary:logistic'],\n",
    "                  'learning_rate': [0.05,0.06,0.1],\n",
    "                  'max_depth': [5, 6],\n",
    "                  'min_child_weight': [1, 3],\n",
    "                  'silent': [1],\n",
    "                  'gamma': [0, 0.1],\n",
    "                  'subsample': [0.6, 0.7, 0.8],\n",
    "                  'colsample_bytree': [0.7, 0.5, 0.6],\n",
    "                  'n_estimators': [5],\n",
    "                  'missing': [-999],\n",
    "                  'seed': [12455]}\n",
    "\n",
    "    clf = GridSearchCV(xgb_model, parameters, n_jobs=1,\n",
    "                       cv=StratifiedKFold(train['orderlabel'], n_folds=5, shuffle=True),\n",
    "                       scoring='roc_auc',\n",
    "                       verbose=2, refit=True)\n",
    "\n",
    "\n",
    "    clf.fit(train_feature, train_label)\n",
    "    best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "    print('AUC score:', score)\n",
    "    for param_name in sorted(best_parameters.keys()):\n",
    "        print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    pickle.dump(best_parameters, open('../result/' + str(score) + '_do_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgbmodel(train,train_val_feature,train_val_index,test,test_index,i,eta,max_depth,rounds,min_child_weight,subsample,colsample_bytree):\n",
    "    if not os.path.exists('../model/new_and_scale_xgb_'+str(i)+'.model'):\n",
    "        train_feature,train_label=train.drop('orderlabel', axis=1), train['orderlabel']\n",
    "        nu=train_label.values\n",
    "        scale_pos_weight = (len(nu[nu == 0])) / float(len(nu[nu == 1]))\n",
    "        parameters = {'nthread': 4,'objective': 'binary:logistic','learning_rate': eta,'max_depth': max_depth,'min_child_weight': min_child_weight,\n",
    "                      'silent': 0,'gamma': 0,'subsample': subsample,'colsample_bytree': colsample_bytree,'n_estimators': 5,\n",
    "                      'missing': -999,'scale_pos_weight': scale_pos_weight,'seed': 4789,'eval_metric':'auc','early_stopping_rounds': 100}\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train_feature,train_label, test_size=0.3, random_state=4789)\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "        bst = xgb.train(parameters, dtrain,num_boost_round=rounds, evals=evallist)\n",
    "        bst.save_model(os.path.join('../model',('new_and_scale_xgb_'+str(i)+'.model')))\n",
    "    else:\n",
    "        bst = xgb.Booster({'nthread': 4})  # init model\n",
    "        bst.load_model('../model/new_and_scale_xgb_'+str(i)+'.model')  # load data\n",
    "\n",
    "    train_val_f=xgb.DMatrix(train_val_feature)\n",
    "    test_f = xgb.DMatrix(test)\n",
    "    train_val_index[str(i)+'_'+'score']=bst.predict(train_val_f)\n",
    "    test_index[str(i)+'_'+'score'] = bst.predict(test_f)\n",
    "    return test_index,train_val_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型准确性评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 评测函数，data列=['orderid','roomid','orderlabel',score_name]\n",
    "def evaluation(data,score_name):\n",
    "    train_val_pred=data.sort_values([score_name], ascending=False).drop_duplicates('orderid').drop([score_name],axis=1).rename(columns={'roomid': 'pred'})\n",
    "    train_val_true=data.loc[data.orderlabel==1,['orderid','roomid']].rename(columns={'roomid': 'true'})\n",
    "    result=pd.merge(train_val_true, train_val_pred, how='inner', on='orderid')\n",
    "    tp=result.loc[result.true==result.pred].shape[0]\n",
    "    return tp/result.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用seaborn 作图查看重要性特征，XGboost.plot_importance()也可以\n",
    "import seaborn as sns\n",
    "def ceate_feature_map(features):\n",
    "    outfile = open('../model/xgb.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "    outfile.close()\n",
    "def  plot_feature_importance(i,j):\n",
    "    bst = xgb.Booster({'nthread': 4})  # init model\n",
    "    bst.load_model('../model/new_and_scale_xgb_' + str(i) + '.model')\n",
    "    importance = bst.get_fscore(fmap='../model/xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=lambda d:d[1], reverse = True)\n",
    "    df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "    df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "    df.to_csv('../model/feat_importance_'+str(i)+'.csv', index=False)\n",
    "    ax=sns.barplot(x='fscore',y='feature',data=df.ix[:j,:])\n",
    "    ax.figure.savefig('../model/images_feature_importance/'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    clean_data('../dataset/competition_train.txt')\n",
    "    clean_data('../dataset/competition_test.txt',istrain=False)\n",
    "    further_clean_data('../dataset/competition_train.txt')\n",
    "    further_clean_data('../dataset/competition_test.txt',istrain=False)\n",
    "    #获取数据\n",
    "    train1,train2,train_val,train_val_index_origin=gene_trainset()\n",
    "    train1,train2,train_val,train_val_index_origin=gene_trainset2()\n",
    "    test,test_index_origin=gene_testset()\n",
    "    test,test_index_origin=gene_testset2()\n",
    "    feature_name=list(train1.columns)\n",
    "    feature_name.remove('orderlabel')\n",
    "    test=test[feature_name]\n",
    "    #train_val=train_val.fillna(-999)\n",
    "    #xgbmodel_train(train_val)\n",
    "    train_val_feature,train_val_label=train_val.drop('orderlabel', axis=1),train_val['orderlabel']\n",
    "    \n",
    "    #最好成绩参数设置，线上score=0.458311\n",
    "    train=pd.concat([train1,train2,train_val],axis=0,ignore_index=True)\n",
    "    test_index,train_val_index=xgbmodel(train,train_val_feature,train_val_index_origin,test,test_index_origin,1,0.1,6,1200,3,0.7,0.5)\n",
    "    pickle.dump(train_val_index,open('../result/new_and_scale_train_val_index_1.pkl','wb'))\n",
    "    pickle.dump(test_index,open('../result/new_and_scale_test_index_1.pkl','wb'))\n",
    "    test_index.to_csv('../result/new_and_scale_test_index_1.csv', index=False)\n",
    "    train_val_index.to_csv('../result/new_and_scale_train_val_index_1.csv', index=False)\n",
    "    print（evaluation(train_val_index,'1_score')）  #Validation set accuracy\n",
    "    #输出最终预测结果\n",
    "    test_index.sort_values(['1_score'], ascending=False).drop_duplicates('orderid').drop(['1_score'],axis=1).to_csv('../result/new_and_scale_1_result.csv',index=None)\n",
    "    ceate_feature_map(feature_name)\n",
    "    plot_feature_importance(1,30)  #输出靠前的30个特征    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
